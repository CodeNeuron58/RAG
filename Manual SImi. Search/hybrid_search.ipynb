{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97abc4f1",
   "metadata": {},
   "source": [
    "### Manual Sparse vs Dense Search Demo\n",
    "\n",
    "This notebook demonstrates the basic ideas behind keyword (sparse) search using TF-IDF\n",
    "and a small dense-embedding example. It shows preprocessing, building TF-IDF sparse\n",
    "representations, computing cosine similarities, and ranking results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727fdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries used for both sparse (TF-IDF) and dense (array) examples\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Note: scikit-learn provides simple utilities for small demos like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ae088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents (small toy corpus)\n",
    "documents = [\n",
    "    \"This is a list which containing sample documents.\",\n",
    "    \"Keywords are important for keyword-based search.\",\n",
    "    \"Document analysis involves extracting keywords.\",\n",
    "    \"Keyword-based search relies on sparse embeddings.\"\n",
    "]\n",
    "\n",
    "# The examples below will show a simple flow: preprocess -> vectorize -> compare -> rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user query\n",
    "query = \"keyword-based search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Simple preprocessing: lowercasing and removing punctuation.\"\"\"\n",
    "    # Convert text to lowercase to make matching case-insensitive\n",
    "    text = text.lower()\n",
    "    # Remove punctuation (keep word characters and whitespace)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# This is intentionally minimal; real pipelines may include tokenization, stemming,\n",
    "# stopword removal, or more advanced normalization depending on needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all documents (apply same function to each document)\n",
    "preprocess_documents = [preprocess_text(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the preprocessed documents so you can inspect what TF-IDF will see\n",
    "preprocess_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessed Documents:\")\n",
    "for doc in preprocess_documents:\n",
    "    print(doc)\n",
    "\n",
    "# This explicit print helps when running cells interactively to confirm preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessed Query (raw):\")\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the query the same way as documents so feature space matches\n",
    "preprocessed_query = preprocess_text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e303b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show preprocessed query\n",
    "preprocessed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer (uses token counts weighted by inverse doc frequency)\n",
    "vector = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on the corpus and transform documents into sparse TF-IDF matrix\n",
    "X = vector.fit_transform(preprocess_documents)\n",
    "\n",
    "# X is a scipy sparse matrix (documents x features). For large corpora we generally keep it sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f416b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to a dense NumPy array only for small demos / inspection\n",
    "dense_X = np.asarray(X.todense())\n",
    "dense_X\n",
    "\n",
    "# Warning: converting to dense does not scale to large datasets. Keep sparse matrices for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the preprocessed query into the same TF-IDF feature space\n",
    "query_embedding = vector.transform([preprocessed_query])\n",
    "\n",
    "# query_embedding is also sparse (1 x n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d71ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want the dense array representation of the query embedding:\n",
    "# query_embedding.toarray()  # uncomment to inspect as dense array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f615422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit convert sparse query embedding to numpy array for compatibility with some APIs\n",
    "np.asarray(query_embedding.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between each document and the query\n",
    "# cosine_similarity handles sparse/dense inputs appropriately (document x features) vs (1 x features)\n",
    "similarities = cosine_similarity(X, query_embedding)\n",
    "similarities\n",
    "\n",
    "# similarities is a column vector (n_docs x 1) containing similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0864974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the sort order (argsort returns indices that would sort the array)\n",
    "np.argsort(similarities, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6088d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking: argsort gives ascending order, so reverse to get descending similarity\n",
    "ranked_indices = np.argsort(similarities, axis=0)[::-1].flatten()\n",
    "\n",
    "# ranked_indices now contains document indices ordered from most to least similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c38c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map indices back to the original document text\n",
    "ranked_documents = [documents[i] for i in ranked_indices]\n",
    "ranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the ranked documents with their rank\n",
    "for i, doc in enumerate(ranked_documents):\n",
    "    print(f\"Rank {i+1}: {doc}\")\n",
    "\n",
    "# In production you'd likely return ids + scores rather than printing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original query for reference\n",
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e60df2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Dense embedding example (toy data)\n",
    "\n",
    "The following section uses small, hand-crafted dense vectors to show how cosine similarity\n",
    "and ranking would work with dense embeddings (e.g., sentence-transformers outputs).\n",
    "This is only illustrative; for real dense embeddings use a model like SentenceTransformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc519a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy documents (re-declared for clarity)\n",
    "documents = [\n",
    "    \"This is a list which containing sample documents.\",\n",
    "    \"Keywords are important for keyword-based search.\",\n",
    "    \"Document analysis involves extracting keywords.\",\n",
    "    \"Keyword-based search relies on sparse embeddings.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: use an embedding model like sentence-transformers in real applications\n",
    "# https://huggingface.co/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small toy dense embeddings (each row is an embedding for a document)\n",
    "document_embeddings = np.array([\n",
    "    [0.634, 0.234, 0.867, 0.042, 0.249],\n",
    "    [0.123, 0.456, 0.789, 0.321, 0.654],\n",
    "    [0.987, 0.654, 0.321, 0.123, 0.456]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f30b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy query represented as a dense vector (1 x dim)\n",
    "query_embedding = np.array([[0.789, 0.321, 0.654, 0.987, 0.123]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between dense query and dense document embeddings\n",
    "similarities = cosine_similarity(document_embeddings, query_embedding)\n",
    "similarities\n",
    "\n",
    "# The resulting array gives similarity per document; higher is more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e613635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show similarity scores\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank indices by similarity (descending)\n",
    "ranked_indices = np.argsort(similarities, axis=0)[::-1].flatten()\n",
    "ranked_indices\n",
    "\n",
    "# You can pair these indices with original document texts or IDs for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d12dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the ranked documents from the dense example\n",
    "for i, idx in enumerate(ranked_indices):\n",
    "    print(f\"Rank {i+1}: Document {idx+1}\")\n",
    "\n",
    "# End of notebook: this simple demo shows the two common building blocks used in\n",
    "# hybrid search (sparse TF-IDF for keywords and dense embeddings for semantic similarity)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
